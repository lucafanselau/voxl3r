{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/luca/uni/master/dl-in-vc/voxl3r'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PYTHONPATH\n",
    "import sys\n",
    "sys.path += ['.', './extern/scannetpp', './extern/mast3r', './extern/mast3r/dust3r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.start_xvfb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last training is bj7r6o9k\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "ckpt_folder = list(\n",
    "        Path(\"./.lightning/surface-net-3d/surface-net-3d/\").glob(\"*\")\n",
    "    )\n",
    "ckpt_folder = sorted(ckpt_folder, key=os.path.getmtime)\n",
    "last_ckpt_folder = ckpt_folder[-1]\n",
    "run_name = last_ckpt_folder.stem\n",
    "print(f\"Last training is {run_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "base_dir = '/home/luca/mnt/data/scannetpp/data'\n",
    "pattern = os.path.join(base_dir, '*', 'prepared_grids', 'dslr', '*furthest_center_1.47')\n",
    "matching_paths = glob.glob(pattern)\n",
    "\n",
    "# Extract the parent directories (two levels up from 'undistorted_images')\n",
    "scenes = [os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(path)))) for path in matching_paths]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No best_ckpts.pt found, falling back to last checkpoint\n",
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 1/64 [00:03<03:29,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/386 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/64 [00:05<02:32,  2.46s/it]/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "  1%|          | 1/124 [00:05<11:21,  5.54s/it]/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 1/63 [00:06<06:57,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected empty mesh. Skipping chunk. Image name: DSC05844.JPG, Scene name: ab11145646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/369 [00:02<14:23,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/477 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m load_yaml_munch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./utils/config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m data_config \u001b[38;5;241m=\u001b[39m SurfaceNet3DDataConfig(data_dir\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_dir, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, scenes\u001b[38;5;241m=\u001b[39mscenes)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mvisualize_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/models/surface_net_3d/run.py:49\u001b[0m, in \u001b[0;36mvisualize_run\u001b[0;34m(run_name, idx_train, idx_val, show, data_config)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Initialize datamodule\u001b[39;00m\n\u001b[1;32m     48\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m SurfaceNet3DDataModule(data_config\u001b[38;5;241m=\u001b[39mdata_config, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/models/surface_net_3d/data.py:462\u001b[0m, in \u001b[0;36mSurfaceNet3DDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    Download or prepare data. Called only on one GPU.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/models/surface_net_3d/data.py:359\u001b[0m, in \u001b[0;36mVoxelGridDataset.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_config\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_config\u001b[38;5;241m.\u001b[39mnum_workers) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_scene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scene_name \u001b[38;5;129;01min\u001b[39;00m scenes:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from models.surface_net_3d.data import SurfaceNet3DDataConfig\n",
    "from models.surface_net_3d.run import visualize_run\n",
    "from utils.data_parsing import load_yaml_munch\n",
    "\n",
    "config = load_yaml_munch(\"./utils/config.yaml\")\n",
    "data_config = SurfaceNet3DDataConfig(data_dir=config.data_dir, batch_size=16, num_workers=1, with_furthest_displacement=True, scenes=scenes, concatinate_pe=True)\n",
    "\n",
    "\n",
    "visualize_run(run_name, 500, 101, show = [\"val\"], data_config=data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: [1.28 1.28 1.28]\n",
      "Center: [0.         0.         1.27999997]\n",
      "Resolution: 0.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset import SceneDataset\n",
    "from models.surface_net_3d.data import SurfaceNet3DDataConfig\n",
    "from utils.chunking import create_chunk, mesh_2_voxels\n",
    "from utils.data_parsing import load_yaml_munch\n",
    "from utils.transformations import invert_pose\n",
    "from utils.visualize import visualize_mesh\n",
    "\n",
    "scene = \"4c5c60fa76\"\n",
    "image_name = \"DSC09946.JPG\"\n",
    "\n",
    "\n",
    "resolution = data_config.grid_resolution\n",
    "grid_size = data_config.grid_size\n",
    "max_seq_len = data_config.seq_len\n",
    "\n",
    "chunk_size = resolution * grid_size.astype(np.float32)\n",
    "center = np.array([0.0, 0.0, chunk_size[2]])\n",
    "\n",
    "dataset = SceneDataset(\n",
    "            camera=data_config.camera,\n",
    "            data_dir=data_config.data_dir,\n",
    "            scenes=data_config.scenes,\n",
    "        )\n",
    "\n",
    "idx = dataset.get_index_from_scene(scene)\n",
    "\n",
    "data = dataset[idx]\n",
    "mesh = data[\"mesh\"]\n",
    "path_images = data[\"path_images\"]\n",
    "camera_params = data[\"camera_params\"]\n",
    "\n",
    "data_chunk = create_chunk(mesh.copy(), image_name, camera_params, max_seq_len=max_seq_len, image_path=path_images, center=center, size=chunk_size, with_backtransform=True)\n",
    "\n",
    "T_cw = camera_params[image_name]['T_cw']\n",
    "_, _, T_wc = invert_pose(T_cw[:3,:3], T_cw[:3,3])\n",
    "\n",
    "mesh_chunk_backtransformer = data_chunk[\"backtransformed\"]\n",
    "mesh_chunk = data_chunk[\"mesh\"]\n",
    "image_names_chunk = data_chunk[\"image_names\"]\n",
    "camera_params_chunk = data_chunk[\"camera_params\"]\n",
    "p_center = data_chunk[\"p_center\"]\n",
    "\n",
    "print(f\"Chunk size: {chunk_size}\")\n",
    "print(f\"Center: {center}\")\n",
    "print(f\"Resolution: {resolution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2201d7b8bc48ab9751e27f41266390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:45793/index.html?ui=P_0x7b19ac3a6e10_3&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_mesh(mesh_chunk_backtransformer, images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: [1.28 1.28 1.28]\n",
      "Center: [0.         0.         1.27999997]\n",
      "Resolution: 0.02\n"
     ]
    }
   ],
   "source": [
    "data_chunk = create_chunk(mesh.copy(), image_name, camera_params, max_seq_len=max_seq_len, image_path=path_images, center=center, size=chunk_size, with_backtransform=True, with_furthest_displacement=True)\n",
    "\n",
    "T_cw = camera_params[image_name]['T_cw']\n",
    "_, _, T_wc = invert_pose(T_cw[:3,:3], T_cw[:3,3])\n",
    "\n",
    "mesh_chunk_backtransformer = data_chunk[\"backtransformed\"]\n",
    "mesh_chunk = data_chunk[\"mesh\"]\n",
    "image_names_chunk = data_chunk[\"image_names\"]\n",
    "camera_params_chunk = data_chunk[\"camera_params\"]\n",
    "p_center = data_chunk[\"p_center\"]\n",
    "\n",
    "print(f\"Chunk size: {chunk_size}\")\n",
    "print(f\"Center: {center}\")\n",
    "print(f\"Resolution: {resolution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b170d3a6404ed0982e31fffb665107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:45793/index.html?ui=P_0x7b19ac3a6c30_4&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_mesh(mesh_chunk_backtransformer, images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupancy values: 10881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0cd0e4fca4405b8d4fb1a228f56550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:45793/index.html?ui=P_0x7b19b4917a40_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "voxel_grid, coordinates, occupancy_values = mesh_2_voxels(mesh_chunk, voxel_size=0.02, to_world_coordinates=T_wc)\n",
    "print(f\"Occupancy values: {occupancy_values.sum()}\")\n",
    "visualize_mesh(voxel_grid.as_boxes(), images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import mesh_2_local_voxels\n",
    "from utils.transformations import invert_pose\n",
    "\n",
    "voxel_grid_local, coordinates_local, occupancy_values_local  = mesh_2_local_voxels(mesh_chunk_backtransformer,  center, 0.02, grid_size[0])\n",
    "visualize_mesh(voxel_grid_local.as_boxes(), images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import mesh_2_local_voxels\n",
    "from utils.transformations import invert_pose\n",
    "\n",
    "\n",
    "T_cw = camera_params[image_name]['T_cw']\n",
    "_, _, T_wc = invert_pose(T_cw[:3,:3], T_cw[:3,3])\n",
    "\n",
    "voxel_grid_local, coordinates_local, occupancy_values_local  = mesh_2_local_voxels(mesh_chunk,  center, 0.02, grid_size[0])\n",
    "visualize_mesh(voxel_grid_local.as_boxes(), images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxl3r-xXnK9ReQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
