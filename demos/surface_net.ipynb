{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/luca/uni/master/dl-in-vc/voxl3r'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PYTHONPATH\n",
    "import sys\n",
    "sys.path += ['.', './extern/scannetpp', './extern/mast3r', './extern/mast3r/dust3r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('trame')\n",
    "\n",
    "from dataset import SceneDataset, SceneDatasetTransformToTorch\n",
    "from einops import rearrange\n",
    "from models.surface_net_baseline.model import SimpleOccNetConfig\n",
    "from models.surface_net_baseline.module import LRConfig, OccSurfaceNet, OptimizerConfig\n",
    "\n",
    "from utils.data_parsing import load_yaml_munch\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightning as pl\n",
    "\n",
    "from utils.visualize import visualize_mesh\n",
    "from utils.basic import get_default_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_seq_len = 16\n",
    "dataset = SceneDataset(\n",
    "        data_dir=\"/home/luca/mnt/data/scannetpp/data\",\n",
    "        camera=\"iphone\",\n",
    "        n_points=300000,\n",
    "        threshold_occ=0.01,\n",
    "        representation=\"occ\",\n",
    "        visualize=True,\n",
    "        max_seq_len=max_seq_len,\n",
    "        resolution=0.02,\n",
    "    )\n",
    "\n",
    "device = get_default_device()\n",
    "transform = SceneDatasetTransformToTorch(target_device=device)\n",
    "idx = dataset.get_index_from_scene(\"0cf2e9402d\")\n",
    "chunks = dataset.chunk_whole_scene(idx, visualize=True)\n",
    "data = chunks[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float64(4.66), np.float64(2.7800000000000002), np.float64(2.6200000000000006))\n",
      "Voxel Grid Center: [2.29 1.35 1.27]\n",
      "Occupied Voxels: 280199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fb38ee87404c13bf1f83770efd50d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada7164ab70_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised\n",
      "KeyError('c8bb90dd40d372ac5325cbab160019fc_105552d')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/wslink/protocol.py\", line 313, in onCompleteMessage\n",
      "    results = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/trame_vtk/modules/vtk/protocols/local_rendering.py\", line 33, in get_array\n",
      "    self.context.get_cached_data_array(data_hash, binary)\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/trame_vtk/modules/vtk/serializers/synchronization_context.py\", line 35, in get_cached_data_array\n",
      "    cache_obj = self.data_array_cache[p_md5]\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "KeyError: 'c8bb90dd40d372ac5325cbab160019fc_105552d'\n",
      "\n",
      "Exception raised\n",
      "KeyError('7868f6cf000339d7210454010c276efb_177350L')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/wslink/protocol.py\", line 313, in onCompleteMessage\n",
      "    results = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/trame_vtk/modules/vtk/protocols/local_rendering.py\", line 33, in get_array\n",
      "    self.context.get_cached_data_array(data_hash, binary)\n",
      "  File \"/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/trame_vtk/modules/vtk/serializers/synchronization_context.py\", line 35, in get_cached_data_array\n",
      "    cache_obj = self.data_array_cache[p_md5]\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "KeyError: '7868f6cf000339d7210454010c276efb_177350L'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import plot_occupency_grid\n",
    "\n",
    "\n",
    "coordinates, occupancy_values = dataset.create_voxel_grid(idx)\n",
    "plot_occupency_grid({\n",
    "  \"training_data\" : (coordinates, occupancy_values),\n",
    "  \"mesh\" : dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f94a34a5eab4534aa4c89460de333cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada7125ae70_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import trimesh\n",
    "\n",
    "mesh = trimesh.load(dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\")\n",
    "boxes = mesh.voxelized(0.02).as_boxes()\n",
    "visualize_mesh(mesh.voxelized(0.02).as_boxes(), opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7606075f9c842fa97a4445aa61d94d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada712f8f20_2&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_mesh(\n",
    "        dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\"\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c1f47de5f2412aa43c2ab77e303675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada712fb7a0_3&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_names, camera_params_list, camera_center = data[\"images\"]\n",
    "\n",
    "visualize_mesh(\n",
    "        data[\"mesh\"],\n",
    "        images=image_names,\n",
    "        camera_params_list=camera_params_list,\n",
    "        point_coords=camera_center,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlupancy Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Transform to Voxel Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float64(2.552727272727274), np.float64(2.0727272727272745), np.float64(1.8527272727272743))\n",
      "Voxel Grid Center: [3.34 1.   0.89]\n",
      "Occupied Voxels: 21668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a1545d3152491a9aae40532e55622b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada70f0af30_4&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import plot_occupency_grid\n",
    "\n",
    "plot_occupency_grid(data, resolution=dataset.resolution / 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project RGB Values to Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/uni/master/dl-in-vc/voxl3r/dataset.py:426: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ]\n",
      "/home/luca/uni/master/dl-in-vc/voxl3r/dataset.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ).to(self.target_device)\n",
      "/home/luca/uni/master/dl-in-vc/voxl3r/models/surface_net_baseline/data.py:103: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at ../aten/src/ATen/Context.cpp:296.)\n",
      "  transformed_points = torch.matmul(transformations, points)\n",
      "/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996cc2d41b324d46becda774fa4e5e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada71687a70_5&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.surface_net_baseline.train import visualize_unprojection\n",
    "\n",
    "visualize_unprojection(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Training Run Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.surface_net_baseline.data import OccSurfaceNetDatamodule\n",
    "\n",
    "\n",
    "datamodule = OccSurfaceNetDatamodule(\n",
    "        dataset,\n",
    "        [\"0cf2e9402d\", \"0cf2e9402d\", \"0cf2e9402d\"],\n",
    "        batch_size=1,\n",
    "        max_sequence_length=max_seq_len,\n",
    "        single_chunk=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "/home/luca/uni/master/dl-in-vc/voxl3r/dataset.py:426: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ]\n",
      "/home/luca/uni/master/dl-in-vc/voxl3r/dataset.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ).to(self.target_device)\n",
      "/home/luca/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float32(2.56), np.float32(2.08), np.float32(1.86))\n",
      "Voxel Grid Center: [3.34 1.   0.89]\n",
      "Occupied Voxels: 22317.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51babfefefba47058c24a0fc472d3e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:46177/index.html?ui=P_0x7ada714789e0_6&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# no pos enc w8mnl00u\n",
    "# pos first 02th0eov\n",
    "from utils.visualize import plot_voxel_grid\n",
    "\n",
    "\n",
    "dict = torch.load(\n",
    "        \"./.lightning/occ-surface-net/surface-net-baseline/lpacvi7v/best_ckpts.pt\"\n",
    "    )\n",
    "model_path = dict[\"best_model_val_accuracy\"]\n",
    "\n",
    "# trainer.test(model_path, dataloaders=datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"test\")\n",
    "\n",
    "model = OccSurfaceNet.load_from_checkpoint(model_path)\n",
    "test_dict = model.test_visualize(datamodule.test_dataloader())\n",
    "\n",
    "gt = torch.cat(test_dict[\"gt\"])\n",
    "points = torch.cat(test_dict[\"points\"])\n",
    "y = torch.sigmoid(torch.cat(test_dict[\"out\"]))\n",
    "y[y < 0.5] = 0.0\n",
    "y[y > 0.5] = 1.0\n",
    "\n",
    "mesh = (\n",
    "    Path(dataset.data_dir)\n",
    "    / dataset.scenes[datamodule.scene_idx_test]\n",
    "    / \"scans\"\n",
    "    / \"mesh_aligned_0.05.ply\"\n",
    ")\n",
    "mesh = None\n",
    "# visualize_mesh(mesh, point_coords=points.cpu().numpy(), heat_values=y.cpu().numpy())\n",
    "plot_voxel_grid(\n",
    "    points.detach().cpu().numpy(),\n",
    "    y.detach().cpu().numpy(),\n",
    "    ref_mesh=mesh,\n",
    "    resolution=dataset.resolution,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/luca/uni/master/dl-in-vc/voxl3r/.lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m scene_dataset\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mOccSurfaceNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m OccSurfaceNetDatamodule(scene_dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8b2c0938d6\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, max_sequence_length\u001b[38;5;241m=\u001b[39mmax_seq_len)\n\u001b[1;32m     11\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1582\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1501\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:63\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     66\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     67\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/lightning/fabric/utilities/cloud_io.py:59\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     55\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     61\u001b[0m         f,\n\u001b[1;32m     62\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/fsspec/spec.py:1301\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1301\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1310\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/fsspec/implementations/local.py:195\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/fsspec/implementations/local.py:359\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/voxl3r-xXnK9ReQ-py3.12/lib/python3.12/site-packages/fsspec/implementations/local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    366\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/luca/uni/master/dl-in-vc/voxl3r/.lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt'"
     ]
    }
   ],
   "source": [
    "from models.surface_net_baseline.data import OccSurfaceNetDatamodule\n",
    "from utils.visualize import plot_voxel_grid\n",
    "\n",
    "max_seq_len = 10\n",
    "scene_dataset = SceneDataset(data_dir=\"datasets/scannetpp/data\", camera=\"iphone\", n_points=300000, threshold_occ=0.01, representation=\"occ\", visualize=True, max_seq_len=max_seq_len)\n",
    "scene_dataset.seed = 42\n",
    "model_path = \".lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt\"\n",
    "\n",
    "model = OccSurfaceNet.load_from_checkpoint(model_path)\n",
    "datamodule = OccSurfaceNetDatamodule(scene_dataset, \"8b2c0938d6\", batch_size=128, max_sequence_length=max_seq_len)\n",
    "datamodule.setup('test')\n",
    "test_dict = model.test_visualize(datamodule.test_dataloader())\n",
    "\n",
    "gt = torch.cat(test_dict['gt'])\n",
    "points = torch.cat(test_dict['points'])\n",
    "y = torch.sigmoid(torch.cat(test_dict['out']))\n",
    "#y[y < 0.5] = 0.0\n",
    "#y[y > 0.5] = 1.0\n",
    "\n",
    "mesh = Path(scene_dataset.data_dir) / scene_dataset.scenes[datamodule.scene_idx] / \"scans\" / \"mesh_aligned_0.05.ply\"\n",
    "visualize_mesh(mesh, point_coords=points.detach().cpu().numpy(), heat_values=y.detach().cpu().numpy())\n",
    "#plot_voxel_grid(points.detach().cpu().numpy(), y.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float32(2.36118), np.float32(2.178124), np.float32(1.2722685))\n",
      "Voxel Grid Center: [3.4625769 2.1568832 1.4368578]\n",
      "Occupied Voxels: 13377.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cece99190048c1981cacfe4bed080c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65377/index.html?ui=P_0x2b1c78c50_5&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "occ = y.clone()\n",
    "occ[y < 0.5] = 0.0\n",
    "occ[y > 0.5] = 1.0\n",
    "plot_voxel_grid(points.detach().cpu().numpy(), occ.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
