{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/luca/uni/master/dl-in-vc/voxl3r'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PYTHONPATH\n",
    "import sys\n",
    "sys.path += ['.', './extern/scannetpp', './extern/mast3r', './extern/mast3r/dust3r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('client')\n",
    "\n",
    "from dataset import SceneDataset, SceneDatasetTransformToTorch\n",
    "from einops import rearrange\n",
    "from models.surface_net_baseline.model import SimpleOccNetConfig\n",
    "from models.surface_net_baseline.module import LRConfig, OccSurfaceNet, OptimizerConfig\n",
    "\n",
    "from utils.data_parsing import load_yaml_munch\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightning as pl\n",
    "\n",
    "from utils.visualize import visualize_mesh\n",
    "from utils.basic import get_default_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SceneDataset.__init__() got an unexpected keyword argument 'data_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSceneDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./datasets/scannetpp/data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miphone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SceneDataset.__init__() got an unexpected keyword argument 'data_dir'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_seq_len = 4\n",
    "dataset = SceneDataset(\n",
    "        data_dir=\"./datasets/scannetpp/data\",\n",
    "        camera=\"iphone\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene dataset output\n",
    "data = dataset[0]\n",
    "mesh = data[\"mesh\"]\n",
    "path_images = data[\"path_images\"]\n",
    "camera_params = data[\"camera_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chunking import create_chunk\n",
    "\n",
    "# get chunk of mesh based of camera\n",
    "data_chunk = create_chunk(mesh.copy(), list(camera_params.keys())[10], camera_params, max_seq_len=8, image_path=path_images, with_backtransform=True)\n",
    "mesh_chunk = data_chunk[\"mesh\"]\n",
    "image_names_chunk = data_chunk[\"image_names\"]\n",
    "camera_params_chunk = data_chunk[\"camera_params\"]\n",
    "p_center = data_chunk[\"p_center\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d3190ea4564f2d8fb7f0d8e91fe7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65081/index.html?ui=P_0x2aa4e12e0_0&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_mesh(mesh_chunk, images=image_names_chunk, camera_params_list=camera_params_chunk.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mesh_2_voxels\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# voxelize mesh and store in training dict\u001b[39;00m\n\u001b[1;32m      4\u001b[0m voxel_grid, coordinates, occupancy_values \u001b[38;5;241m=\u001b[39m mesh_2_voxels(mesh_chunk, voxel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m)\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/utils/chunking.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrimesh\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurface_net_3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m project_voxel_grid_to_images_seperate\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m invert_pose, project_image_plane\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_images_with_3d_point\u001b[39m(\n\u001b[1;32m     15\u001b[0m     points, camera_params, keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     16\u001b[0m ):\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/models/surface_net_3d/projection.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SceneDataset, SceneDatasetTransformToTorch\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Subset\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/dataset.py:18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_image\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextern\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscannetpp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscene_release\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScannetppScene_Release\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextern\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscannetpp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miphone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprepare_iphone_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     extract_depth,\n\u001b[1;32m     20\u001b[0m     extract_masks,\n\u001b[1;32m     21\u001b[0m     extract_rgb,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_parsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     get_camera_params,\n\u001b[1;32m     25\u001b[0m     get_image_names_with_extrinsics,\n\u001b[1;32m     26\u001b[0m     get_vertices_labels,\n\u001b[1;32m     27\u001b[0m     load_yaml_munch,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmasking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_mask, get_structures_unstructured_mesh\n",
      "File \u001b[0;32m~/uni/master/dl-in-vc/voxl3r/extern/scannetpp/iphone/prepare_iphone_data.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01miio\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlz4\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscene_release\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScannetppScene_Release\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_command, load_yaml_munch, load_json, read_txt_list\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_rgb\u001b[39m(scene):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common'"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.chunking import mesh_2_voxels\n",
    "\n",
    "# voxelize mesh and store in training dict\n",
    "voxel_grid, coordinates, occupancy_values = mesh_2_voxels(mesh_chunk, voxel_size=0.02)\n",
    "\n",
    "trainings_dict = {\n",
    "    \"mesh\": mesh_chunk,\n",
    "    \"training_data\" : (coordinates, occupancy_values),\n",
    "    \"images\" : (image_names_chunk, camera_params_chunk.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09264a83dc949a7a693a9e8b88b8607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65081/index.html?ui=P_0x2aafa6b10_4&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_mesh(voxel_grid.as_boxes(), images=image_names_chunk, camera_params_list=camera_params_chunk.values(), opacity=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_mesh(voxel_grid.as_boxes(), point_coords=coordinates[occupancy_values == 1], images=image_names_chunk, camera_params_list=camera_params_chunk.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  points = torch.tensor(torch.from_numpy(points).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:113: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt = torch.tensor(torch.from_numpy(gt).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6a76fe9ff440fb9e75a7a09e9687b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65081/index.html?ui=P_0x2aaefad80_5&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.surface_net_baseline.train import visualize_unprojection\n",
    "\n",
    "visualize_unprojection(trainings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.surface_net_baseline.train import visualize_unprojection_whole_scene\n",
    "\n",
    "\n",
    "visualize_unprojection_whole_scene(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import plot_occupency_grid\n",
    "\n",
    "\n",
    "coordinates, occupancy_values = dataset.create_voxel_grid(idx)\n",
    "plot_occupency_grid({\n",
    "  \"training_data\" : (coordinates, occupancy_values),\n",
    "  \"mesh\" : dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "mesh = trimesh.load(dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\")\n",
    "voxel_grid = mesh.voxelized(0.02)\n",
    "boxes = voxel_grid.as_boxes()\n",
    "visualize_mesh(mesh.voxelized(0.02).as_boxes(), opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mesh(\n",
    "        dataset.data_dir / dataset.scenes[idx] / \"scans\" / \"mesh_aligned_0.05.ply\"\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names, camera_params_list, camera_center = data[\"images\"]\n",
    "\n",
    "visualize_mesh(\n",
    "        data[\"mesh\"],\n",
    "        images=image_names,\n",
    "        camera_params_list=camera_params_list,\n",
    "        point_coords=camera_center,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlupancy Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Transform to Voxel Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import plot_occupency_grid\n",
    "\n",
    "plot_occupency_grid(data, resolution=dataset.resolution / 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project RGB Values to Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.surface_net_baseline.train import visualize_unprojection\n",
    "\n",
    "visualize_unprojection(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Training Run Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.surface_net_baseline.data import OccSurfaceNetDatamodule\n",
    "\n",
    "\n",
    "datamodule = OccSurfaceNetDatamodule(\n",
    "        dataset,\n",
    "        [\"0cf2e9402d\", \"0cf2e9402d\", \"0cf2e9402d\"],\n",
    "        batch_size=1,\n",
    "        max_sequence_length=max_seq_len,\n",
    "        single_chunk=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pos enc w8mnl00u\n",
    "# pos first 02th0eov\n",
    "from utils.visualize import plot_voxel_grid\n",
    "\n",
    "\n",
    "dict = torch.load(\n",
    "        \"./.lightning/occ-surface-net/surface-net-baseline/lpacvi7v/best_ckpts.pt\"\n",
    "    )\n",
    "model_path = dict[\"best_model_val_accuracy\"]\n",
    "\n",
    "# trainer.test(model_path, dataloaders=datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"test\")\n",
    "\n",
    "model = OccSurfaceNet.load_from_checkpoint(model_path)\n",
    "test_dict = model.test_visualize(datamodule.test_dataloader())\n",
    "\n",
    "gt = torch.cat(test_dict[\"gt\"])\n",
    "points = torch.cat(test_dict[\"points\"])\n",
    "y = torch.sigmoid(torch.cat(test_dict[\"out\"]))\n",
    "y[y < 0.5] = 0.0\n",
    "y[y > 0.5] = 1.0\n",
    "\n",
    "mesh = (\n",
    "    Path(dataset.data_dir)\n",
    "    / dataset.scenes[datamodule.scene_idx_test]\n",
    "    / \"scans\"\n",
    "    / \"mesh_aligned_0.05.ply\"\n",
    ")\n",
    "mesh = None\n",
    "# visualize_mesh(mesh, point_coords=points.cpu().numpy(), heat_values=y.cpu().numpy())\n",
    "plot_voxel_grid(\n",
    "    points.detach().cpu().numpy(),\n",
    "    y.detach().cpu().numpy(),\n",
    "    ref_mesh=mesh,\n",
    "    resolution=dataset.resolution,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.surface_net_baseline.data import OccSurfaceNetDatamodule\n",
    "from utils.visualize import plot_voxel_grid\n",
    "\n",
    "max_seq_len = 10\n",
    "scene_dataset = SceneDataset(data_dir=\"datasets/scannetpp/data\", camera=\"iphone\", n_points=300000, threshold_occ=0.01, representation=\"occ\", visualize=True, max_seq_len=max_seq_len)\n",
    "scene_dataset.seed = 42\n",
    "model_path = \".lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt\"\n",
    "\n",
    "model = OccSurfaceNet.load_from_checkpoint(model_path)\n",
    "datamodule = OccSurfaceNetDatamodule(scene_dataset, \"8b2c0938d6\", batch_size=128, max_sequence_length=max_seq_len)\n",
    "datamodule.setup('test')\n",
    "test_dict = model.test_visualize(datamodule.test_dataloader())\n",
    "\n",
    "gt = torch.cat(test_dict['gt'])\n",
    "points = torch.cat(test_dict['points'])\n",
    "y = torch.sigmoid(torch.cat(test_dict['out']))\n",
    "#y[y < 0.5] = 0.0\n",
    "#y[y > 0.5] = 1.0\n",
    "\n",
    "mesh = Path(scene_dataset.data_dir) / scene_dataset.scenes[datamodule.scene_idx] / \"scans\" / \"mesh_aligned_0.05.ply\"\n",
    "visualize_mesh(mesh, point_coords=points.detach().cpu().numpy(), heat_values=y.detach().cpu().numpy())\n",
    "#plot_voxel_grid(points.detach().cpu().numpy(), y.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = y.clone()\n",
    "occ[y < 0.5] = 0.0\n",
    "occ[y > 0.5] = 1.0\n",
    "plot_voxel_grid(points.detach().cpu().numpy(), occ.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxl3r-xXnK9ReQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
