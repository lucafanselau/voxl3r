{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luis/uni/dl-vc/voxl3r'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup PYTHONPATH\n",
    "import sys\n",
    "sys.path += ['.', './extern/scannetpp', './extern/mast3r', './extern/mast3r/dust3r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('client')\n",
    "\n",
    "from dataset import SceneDataset, SceneDatasetTransformToTorch\n",
    "from einops import rearrange\n",
    "from models.surface_net_baseline.model import SimpleOccNetConfig\n",
    "from models.surface_net_baseline.module import LRConfig, OccSurfaceNet, OptimizerConfig\n",
    "from utils.data_parsing import load_yaml_munch\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightning as pl\n",
    "\n",
    "from utils.visualize import visualize_mesh\n",
    "from utils.basic import get_default_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "# Init dataset and load for visualization\n",
    "dataset_tdf = SceneDataset(\n",
    "    data_dir=\"datasets/scannetpp/data\",\n",
    "    camera=\"iphone\",\n",
    "    n_points=300000,\n",
    "    threshold_occ=0.01,\n",
    "    representation=\"tdf\",\n",
    "    visualize=True,\n",
    "    max_seq_len=10,\n",
    ")\n",
    "\n",
    "dataset = SceneDataset(\n",
    "    data_dir=\"datasets/scannetpp/data\",\n",
    "    camera=\"iphone\",\n",
    "    n_points=300000,\n",
    "    threshold_occ=0.01,\n",
    "    representation=\"occ\",\n",
    "    visualize=True,\n",
    "    max_seq_len=10,\n",
    ")\n",
    "\n",
    "device = get_default_device()\n",
    "transform = SceneDatasetTransformToTorch(target_device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dataset_tdf.get_index_from_scene(\"8b2c0938d6\")\n",
    "data = dataset_tdf[idx]\n",
    "data_occ = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9623d571d80841c2b114adb6810d72a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2ab2997f0_0&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_names, camera_params_list, camera_center = data[\"images\"]\n",
    "\n",
    "visualize_mesh(\n",
    "        data[\"mesh\"],\n",
    "        images=image_names,\n",
    "        camera_params_list=camera_params_list,\n",
    "        point_coords=camera_center,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95e8c7308914d91b59f1d19faae925a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2ab3b68d0_1&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import plot_training_example\n",
    "\n",
    "plot_training_example(data, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float64(2.5427338302733933), np.float64(2.36019887287575), np.float64(1.4127689768822693))\n",
      "Voxel Grid Center: [3.33985962 2.48516048 1.36397003]\n",
      "Occupied Voxels: 4380.346921073418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0a5239906043e28c0664d2c38d79e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2abf6a0f0_2&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import plot_occupency_grid\n",
    "\n",
    "plot_occupency_grid(data, idx, resolution=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:293: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  points = torch.tensor(torch.from_numpy(points).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:294: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt = torch.tensor(torch.from_numpy(gt).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/Users/luis/uni/dl-vc/voxl3r/models/surface_net_baseline/data.py:54: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:361.)\n",
      "  sampled[~mask] = fill_value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80b66d527ff462387cab0d4b83e1645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2b09dac90_3&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.surface_net_baseline.train import visualize_unprojection\n",
    "\n",
    "visualize_unprojection(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:293: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  points = torch.tensor(torch.from_numpy(points).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/dataset.py:294: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt = torch.tensor(torch.from_numpy(gt).float()).to(self.target_device)\n",
      "/Users/luis/uni/dl-vc/voxl3r/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d815f8760b46888942303cf2d22844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2b0d1cfb0_4&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.surface_net_baseline.data import OccSurfaceNetDatamodule\n",
    "from utils.visualize import plot_voxel_grid\n",
    "\n",
    "max_seq_len = 10\n",
    "scene_dataset = SceneDataset(data_dir=\"datasets/scannetpp/data\", camera=\"iphone\", n_points=300000, threshold_occ=0.01, representation=\"occ\", visualize=True, max_seq_len=max_seq_len)\n",
    "scene_dataset.seed = 42\n",
    "model_path = \".lightning/occ-surface-net/surface-net-baseline/r3cf6z5t/checkpoints/epoch=262-step=24459.00-val_accuracy=0.89.ckpt\"\n",
    "\n",
    "model = OccSurfaceNet.load_from_checkpoint(model_path)\n",
    "datamodule = OccSurfaceNetDatamodule(scene_dataset, \"8b2c0938d6\", batch_size=128, max_sequence_length=max_seq_len)\n",
    "datamodule.setup('test')\n",
    "test_dict = model.test_visualize(datamodule.test_dataloader())\n",
    "\n",
    "gt = torch.cat(test_dict['gt'])\n",
    "points = torch.cat(test_dict['points'])\n",
    "y = torch.sigmoid(torch.cat(test_dict['out']))\n",
    "#y[y < 0.5] = 0.0\n",
    "#y[y > 0.5] = 1.0\n",
    "\n",
    "mesh = Path(scene_dataset.data_dir) / scene_dataset.scenes[datamodule.scene_idx] / \"scans\" / \"mesh_aligned_0.05.ply\"\n",
    "visualize_mesh(mesh, point_coords=points.detach().cpu().numpy(), heat_values=y.detach().cpu().numpy())\n",
    "#plot_voxel_grid(points.detach().cpu().numpy(), y.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Grid Size (L, W, H): (np.float32(2.36118), np.float32(2.178124), np.float32(1.2722685))\n",
      "Voxel Grid Center: [3.4625769 2.1568832 1.4368578]\n",
      "Occupied Voxels: 13377.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d023334732545afbc8d110be49a3ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:65046/index.html?ui=P_0x2b0846450_5&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "occ = y.clone()\n",
    "occ[y < 0.5] = 0.0\n",
    "occ[y > 0.5] = 1.0\n",
    "plot_voxel_grid(points.detach().cpu().numpy(), occ.detach().cpu().numpy(), ref_mesh=mesh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
